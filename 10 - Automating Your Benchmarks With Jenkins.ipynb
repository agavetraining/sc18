{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/agave/funwave-tvd-jenkins-pipeline\n",
    "\n",
    "%cd ~/agave/funwave-tvd-jenkins-pipeline\n",
    "\n",
    "!pip3 install --upgrade setvar\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from setvar import *\n",
    "\n",
    "# This cell enables inline plotting in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!auth-tokens-refresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Your Build\n",
    "* Automation is great, but things can quickly go wrong.\n",
    "* This is why CI/CD strongly emphasizes good testing practices.\n",
    "* Testing is central to CI/CD\n",
    "  * It allows you assess viability of each commit\n",
    "  * It is the determination of whether or not code can be successfully integrated\n",
    "  * It allows for code to be automatically deployed to prod, without the direct oversight of a tightly controlled group of developers.\n",
    "* Production pipelines have multiple testing guards\n",
    "  * Types of tests: Unit, Functional, Acceptance, Benchmarks, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Benchmark\n",
    "* Let's add a simple benchmark to validate performance after each build.\n",
    "* We'll make a new feature branch for this benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh sandbox \"cd ~/FUNWAVE-TVD && git checkout -b benchmark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We're going to need new input files in order to run a strong scaling study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2,1] means PX=1, PY=1,2 total processors\n",
    "for np in [[1,1], [2,1], [2,2]]:\n",
    "    writefile(\"input_{NP}.txt\".format(NP=int(np[0]*np[1])),\"\"\"\n",
    "!INPUT FILE FOR FUNWAVE_TVD\n",
    "  ! NOTE: all input parameter are capital sensitive\n",
    "  ! --------------------TITLE-------------------------------------\n",
    "  ! title only for log file\n",
    "TITLE = VESSEL\n",
    "  ! -------------------HOT START---------------------------------\n",
    "HOT_START = F\n",
    "FileNumber_HOTSTART = 1\n",
    "  ! -------------------PARALLEL INFO-----------------------------\n",
    "  !\n",
    "  !    PX,PY - processor numbers in X and Y\n",
    "  !    NOTE: make sure consistency with mpirun -np n (px*py)\n",
    "  !\n",
    "PX = {PX}\n",
    "PY = {PY}\n",
    "  ! --------------------DEPTH-------------------------------------\n",
    "  ! Depth types, DEPTH_TYPE=DATA: from depth file\n",
    "  !              DEPTH_TYPE=FLAT: idealized flat, need depth_flat\n",
    "  !              DEPTH_TYPE=SLOPE: idealized slope,\n",
    "  !                                 need slope,SLP starting point, Xslp\n",
    "  !                                 and depth_flat\n",
    "DEPTH_TYPE = FLAT\n",
    "DEPTH_FLAT = 10.0\n",
    "  ! -------------------PRINT---------------------------------\n",
    "  ! PRINT*,\n",
    "  ! result folder\n",
    "RESULT_FOLDER = output/\n",
    "\n",
    "  ! ------------------DIMENSION-----------------------------\n",
    "  ! global grid dimension\n",
    "Mglob = 500\n",
    "Nglob = 100\n",
    "\n",
    "  ! ----------------- TIME----------------------------------\n",
    "  ! time: total computational time/ plot time / screen interval\n",
    "  ! all in seconds\n",
    "TOTAL_TIME = 3.0\n",
    "PLOT_INTV = 1.0\n",
    "PLOT_INTV_STATION = 50000.0\n",
    "SCREEN_INTV = 1.0\n",
    "HOTSTART_INTV = 360000000000.0\n",
    "\n",
    "WAVEMAKER = INI_GAU\n",
    "AMP = 3.0\n",
    "Xc = 250.0\n",
    "Yc = 50.0\n",
    "WID = 20.0\n",
    "\n",
    "  ! -----------------GRID----------------------------------\n",
    "  ! if use spherical grid, in decimal degrees\n",
    "  ! cartesian grid sizes\n",
    "DX = 1.0\n",
    "DY = 1.0\n",
    "  ! ----------------SHIP WAKES ----------------------------\n",
    "VESSEL_FOLDER = ./\n",
    "NumVessel = 2\n",
    "  ! -----------------OUTPUT-----------------------------\n",
    "ETA = T\n",
    "U = T\n",
    "V = T\n",
    "\"\"\".format(PX=np[0], PY=np[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll make directories to store our input files and outputs from benchmarking runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N /home/jovyan/FUNWAVE-TVD/benchmarks/np_1\n",
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N /home/jovyan/FUNWAVE-TVD/benchmarks/np_2\n",
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N /home/jovyan/FUNWAVE-TVD/benchmarks/np_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading our new input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!files-upload -F input_1.txt -S ${AGAVE_STORAGE_SYSTEM_ID} /home/jovyan/FUNWAVE-TVD/benchmarks/np_1/\n",
    "!files-upload -F input_2.txt -S ${AGAVE_STORAGE_SYSTEM_ID} /home/jovyan/FUNWAVE-TVD/benchmarks/np_2/\n",
    "!files-upload -F input_4.txt -S ${AGAVE_STORAGE_SYSTEM_ID} /home/jovyan/FUNWAVE-TVD/benchmarks/np_4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"funwave-benchmark-wrapper.txt\",\"\"\"\n",
    "\n",
    "VERSION=$(cat version.txt | paste -sd \".\" -)\n",
    "\n",
    "export BASE_DIR=$PWD \n",
    "for np in {1,2,4}; do\n",
    "  cd ${BASE_DIR}/np_${np}\n",
    "  docker run funwave-tvd:\\${VERSION} mpirun -np $np /home/install/FUNWAVE-TVD/src/funwave_vessel\n",
    "\"\"\")\n",
    "!files-upload -S ${AGAVE_STORAGE_SYSTEM_ID} -F funwave-benchmark-wrapper.txt /home/jovyan/FUNWAVE-TVD/build/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"funwave-benchmark-app.txt\",\"\"\"\n",
    "{  \n",
    "   \"name\":\"${AGAVE_USERNAME}-${MACHINE_NAME}-funwave-dbuild\",\n",
    "   \"version\":\"1.0\",\n",
    "   \"label\":\"Benchmarks the funwave docker image\",\n",
    "   \"shortDescription\":\"Funwave docker benchmark\",\n",
    "   \"longDescription\":\"\",\n",
    "   \"deploymentSystem\":\"${AGAVE_STORAGE_SYSTEM_ID}\",\n",
    "   \"deploymentPath\":\"automation/funwave-tvd-docker-automation\",\n",
    "   \"templatePath\":\"build/funwave-benchmark-wrapper.txt\",\n",
    "   \"testPath\":\"test.txt\",\n",
    "   \"executionSystem\":\"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"executionType\":\"CLI\",\n",
    "   \"parallelism\":\"SERIAL\",\n",
    "   \"modules\":[],\n",
    "   \"inputs\":[],\n",
    "   \"parameters\":[{\n",
    "     \"id\" : \"code_version\",\n",
    "     \"value\" : {\n",
    "       \"visible\":true,\n",
    "       \"required\":true,\n",
    "       \"type\":\"string\",\n",
    "       \"order\":0,\n",
    "       \"enquote\":false,\n",
    "       \"default\":\"latest\"\n",
    "     },\n",
    "     \"details\":{\n",
    "         \"label\": \"Version of the code\",\n",
    "         \"description\": \"If true, output will be packed and compressed\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     },\n",
    "     \"semantics\":{\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     }\n",
    "   }],\n",
    "   \"outputs\":[]\n",
    "}\n",
    "\"\"\")\n",
    "!files-upload -S ${AGAVE_STORAGE_SYSTEM_ID} -F funwave-benchmark-app.txt /home/jovyan/FUNWAVE-TVD/build/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating Our Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add A Jenkinsfile to Run the Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!files-upload -S ${AGAVE_STORAGE_SYSTEM_ID} -F /home/jovyan/notebooks/build/Jenkinsfile-benchmark /home/jovyan/FUNWAVE-TVD/build/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRYing Out Our Jenkinsfiles\n",
    "Both our build and benchmark Jenkinsfiles are following the same basic workflow _(checkout code, setup Agave CLI, build and submit job to execution environment)_ which has resulted in a bunch of duplicated code that varies only by a keyword. For the sake of maintainability, we should find a way to improve the orthogonality of our pipeline.\n",
    "\n",
    "## Jenkins Shared Libraries\n",
    "A [Jenkins Shared Library](https://jenkins.io/doc/book/pipeline/shared-libraries/) is a repository of code that is centrally managed, and made accessible to multiple pipelines. These pipelines can call shared libraries as functions, and pass parameters to specify build options.\n",
    "\n",
    "## Update the Build Jenkinsfile to Trigger the Benchmark\n",
    "* We need to add a new stage to the Jenkins pipeline to run the benchmark if the preceeding stages of the build executed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile(\"Jenkinsfile\", \"\"\"import groovy.json.JsonOutput\n",
    "\n",
    "def JobStages = load(\"JobStages.groovy\")\n",
    "\n",
    "\n",
    "node {\n",
    "  currentBuild.result = \"SUCCESS\"\n",
    "\n",
    "  env.AGAVE_TENANTS_API_BASEURL = \"https://sandbox.agaveplatform.org/tenants\"\n",
    "  env.MACHINE_NAME = \"sandbox\"\n",
    "  env.AGAVE_APP_NAME = \"funwave-tvd-build-\\${env.AGAVE_USERNAME}\"\n",
    "  env.AGAVE_CLIENT_NAME = \"jenkins-cli-\\${env.AGAVE_USERNAME}\"\n",
    "\n",
    "  try {\n",
    "\n",
    "    JobStages.setUpCli(env)\n",
    "    JobStages.cloneRepository()\n",
    "    JobStages.updateApp('build', env)\n",
    "    JobStages.submitJob('build', env)\n",
    "\n",
    "    stage(\"Run benchmarks\") {\n",
    "      // Benchmarking stuff goes here\n",
    "    }\n",
    "\n",
    "  } catch (error) {\n",
    "\n",
    "    currentBuild.result = \"FAILURE\"\n",
    "    throw error\n",
    "\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "!files-upload -S ${AGAVE_STORAGE_SYSTEM_ID} -F Jenkinsfile /home/jovyan/FUNWAVE-TVD/build/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit Your Benchmark, Watch It Run\n",
    "* Let's merge our benchmark back into the `dev` branch and watch it run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh sandbox \"set -x && cd ~/FUNWAVE-TVD && git add build\"\n",
    "!ssh sandbox \"cd ~/FUNWAVE-TVD && git commit -m 'Added benchmark app and pipeline.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh sandbox \"cd ~/FUNWAVE-TVD && git checkout dev && git merge --squash benchmark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Our Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create functions to gather our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_from_output(output):\n",
    "    '''output: list output from funwave split by lines\n",
    "    ex: [\"line1\", \"line2\", ...]\n",
    "    returns a float of simulation time if it exists'''\n",
    "    for line in output:\n",
    "        if \"simulation\" in line.lower():\n",
    "            line = ' '.join(line.lower().split())\n",
    "            split_line = line.split()\n",
    "            time = float(split_line[2])\n",
    "            return time\n",
    "    return \"No timing result found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(output):\n",
    "    '''output: list output from funwave split by lines\n",
    "    ex: [\"line1\", \"line2\", ...]\n",
    "    returns the date and commit of the run'''\n",
    "    date = ''\n",
    "    commit = ''\n",
    "    for line in output:\n",
    "        if \"funwave run date\" in line.lower():\n",
    "            line = ' '.join(line.lower().split())\n",
    "            split_line = line.split()\n",
    "            date = split_line[-1]\n",
    "        if \"funwave commit hash\" in line.lower():\n",
    "            line = ' '.join(line.lower().split())\n",
    "            split_line = line.split()\n",
    "            commit = split_line[-1]\n",
    "    return date + '_' + commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_funwave(metadata, results):\n",
    "    '''metadata: list of date_commits to plot (x-axis)\n",
    "    ex: ['day1_commit1', 'day2_commit2', 'day3_commit2']\n",
    "    results: dict of floats containing simulation times from funwave\n",
    "    ex: results[1] = [57.45267612299358, 58.964640157995746, 57.09651633500471]\n",
    "    results[2] = [16.213947223004652, 16.57105119198968, 15.723207671995624]\n",
    "    The lists in results should be the same length as the metadata list!\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    for np in [1, 2, 4]:\n",
    "        plt.plot( metadata, results[np], marker='o', markersize=12, linewidth=2, label=np)\n",
    "\n",
    "    plt.title('Funwave Strong Scaling Time vs Commit')\n",
    "    plt.legend(loc='upper left', title=\"NP\", bbox_to_anchor=(1,1))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
